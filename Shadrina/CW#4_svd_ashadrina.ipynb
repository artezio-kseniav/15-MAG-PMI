{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06.06 Classwork №4: Cингулярное разложение и Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "cats = ['alt.atheism', 'rec.motorcycles',  'rec.autos', 'sci.electronics']\n",
    "dataset = fetch_20newsgroups(categories=cats, subset='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset categories:  ['alt.atheism', 'rec.autos', 'rec.motorcycles', 'sci.electronics']\n",
      "Dataset texts:  3769\n"
     ]
    }
   ],
   "source": [
    "print (\"Dataset categories: \", dataset.target_names)\n",
    "print (\"Dataset texts: \", len(dataset.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Векторизация и сингулярное разложение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "X_tfidf = tfidf.fit_transform(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "n_comp = 10\n",
    "svd = TruncatedSVD(n_components=n_comp)\n",
    "X_svd = svd.fit_transform(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3769, 10)\n",
      "[[  5.40635309e-03   1.09778971e-02   2.51324104e-04 ...,   2.12522492e-04\n",
      "    2.06266117e-04   2.06266117e-04]\n",
      " [  9.93053031e-03   1.79756417e-02   8.26957258e-04 ...,   4.12102399e-04\n",
      "    3.35655130e-04   3.35655130e-04]\n",
      " [  4.72569250e-03   2.63779571e-04   6.41619660e-04 ...,   1.91137403e-04\n",
      "    3.88905662e-04   3.88905662e-04]\n",
      " ..., \n",
      " [  1.80630693e-03   2.18007139e-02  -9.47554897e-04 ...,   9.24762463e-05\n",
      "   -1.09704778e-03  -1.09704778e-03]\n",
      " [  1.60778310e-02   1.06610561e-02   1.01579050e-03 ...,  -2.61294700e-04\n",
      "    2.39940632e-03   2.39940632e-03]\n",
      " [ -6.21291720e-03  -7.48404779e-03   3.20521518e-04 ...,   5.25722813e-05\n",
      "   -1.02095604e-03  -1.02095604e-03]]\n"
     ]
    }
   ],
   "source": [
    "print (X_svd.shape)\n",
    "print (svd.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2638 1131\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "y = dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_svd, y, test_size = 0.3, random_state = 1)\n",
    "\n",
    "N_train, _ = X_train.shape \n",
    "N_test,  _ = X_test.shape \n",
    "\n",
    "print (N_train, N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.103487490523 0.14765694076\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier().fit(X_train, y_train)\n",
    "\n",
    "y_train_predict = knn.predict(X_train)\n",
    "y_test_predict = knn.predict(X_test)\n",
    "\n",
    "err_train = np.mean(y_train != y_train_predict)\n",
    "err_test  = np.mean(y_test  != y_test_predict)\n",
    "\n",
    "print (err_train, err_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.93      0.95       220\n",
      "          1       0.80      0.81      0.80       317\n",
      "          2       0.83      0.85      0.84       299\n",
      "          3       0.84      0.84      0.84       295\n",
      "\n",
      "avg / total       0.85      0.85      0.85      1131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Интерпретация топиков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular words in category # 1 ['edu' 'you' 'it' 'in' 'that' 'is' 'and' 'of' 'to']\n",
      "Most popular words in category # 2 ['hp' 'dod' 'sun' 'com' 'ca' 'my' 'on' 'bike' 'car']\n",
      "Most popular words in category # 3 ['jon' 'wpd' 'solntze' 'caltech' 'sun' 'livesey' 'keith' 'sgi' 'edu']\n",
      "Most popular words in category # 4 ['god' 'to' 'her' 'egreen' 'green' 'com' 'ed' 'you' 'east']\n",
      "Most popular words in category # 5 ['sun' 'was' 'caltech' 'com' 'wpd' 'solntze' 'jon' 'livesey' 'sgi']\n",
      "Most popular words in category # 6 ['my' 'nec' 'have' 'ca' 'behanna' 'livesey' 'sgi' 'to' 'car']\n",
      "Most popular words in category # 7 ['bike' 'ca' 'bnr' 'demon' 'nec' 'behanna' 'co' 'morgan' 'tony']\n",
      "Most popular words in category # 8 ['nec' 'beauchaine' 'bobbe' 'behanna' 'sandvik' 'vice' 'he' 'ico' 'tek']\n",
      "Most popular words in category # 9 ['kent' 'hp' 'beauchaine' 'bobbe' 'vice' 'ico' 'tek' 'sandvik' 'uk']\n",
      "Most popular words in category # 10 ['vice' 'ico' 'allan' 'pasadena' 'schneider' 'cco' 'morality' 'the'\n",
      " 'caltech']\n"
     ]
    }
   ],
   "source": [
    "for i_t,i in enumerate(svd.components_,1):\n",
    "    ind = np.argsort(i)\n",
    "    print (\"Most popular words in category #\",i_t,np.asarray(tfidf.get_feature_names())[ind[-10:-1]][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "dataset_tokenized = [nltk.word_tokenize(text) for text in dataset.data]\n",
    "\n",
    "texts = []\n",
    "for text in dataset_tokenized:\n",
    "    lemms = []\n",
    "    for word in text:\n",
    "        if word not in string.punctuation:\n",
    "            lemms.append(word.lower())\n",
    "    texts.append(lemms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3769 134 428\n"
     ]
    }
   ],
   "source": [
    "print (len(texts), len(texts[0]), len(texts[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda\\lib\\site-packages\\gensim\\models\\word2vec.py:691: UserWarning: C extension not loaded for Word2Vec, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  warnings.warn(\"C extension not loaded for Word2Vec, training will be slow. \"\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('motorcycle', 0.8870781660079956),\n",
       " ('lubed', 0.8047821521759033),\n",
       " ('head', 0.7949617505073547),\n",
       " ('wife', 0.7829919457435608),\n",
       " ('seat', 0.7651523947715759),\n",
       " ('wallet', 0.7623045444488525),\n",
       " ('hands', 0.7563285827636719),\n",
       " ('dog', 0.7508450746536255),\n",
       " ('frame', 0.7453364133834839),\n",
       " ('house', 0.7442944049835205)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['honda', 'helmet'], negative=['auto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"pc tablet cluster dog\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'motherboard'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"circuit motherboard screen code\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот и нет. Лишнее слово тут - cat. Всё остальное относится к компьютерам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85874348349521235"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('god', 'satan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0184273 ,  0.00619601, -0.42118284,  0.28704453,  0.58555907,\n",
       "       -0.21817216,  0.08192006,  0.01356775, -0.1778322 , -0.15329054,\n",
       "       -0.12459341,  0.18103896, -0.03870576, -0.1133403 ,  0.11081257,\n",
       "       -0.01971509, -0.12565637,  0.0716049 , -0.54352778, -0.20821916,\n",
       "       -0.2454417 , -0.06420164, -0.09143994,  0.23850578, -0.37113723,\n",
       "       -0.14094523, -0.3717812 ,  0.41719395,  0.13052195, -0.24853545,\n",
       "        0.39064136, -0.58536935, -0.18217732,  0.0215153 , -0.24226755,\n",
       "        0.42140931,  0.0378667 ,  0.34588763, -0.48749039, -0.37451002,\n",
       "        0.17843001,  0.40116221, -0.27440837,  0.14714156,  0.33964202,\n",
       "        0.34375665, -0.49631339, -0.55757093, -0.08487422, -0.31132206,\n",
       "        0.06261025,  0.16420554,  0.10875834, -0.06008864,  0.16958977,\n",
       "        0.31347817, -0.28694597,  0.0787242 , -0.38555342, -0.17179225,\n",
       "       -0.24191099, -0.05923447,  0.04102996,  0.02831565,  0.21226011,\n",
       "       -0.1936094 ,  0.00486322, -0.07231928, -0.12243412,  0.13600372,\n",
       "        0.26842418,  0.5245676 ,  0.08545648, -0.40134898, -0.50890595,\n",
       "       -0.36927962,  0.0296259 ,  0.33042696, -0.34887624,  0.37582201,\n",
       "        0.01033544, -0.21584907, -0.57725483,  0.23395355,  0.246749  ,\n",
       "        0.10093574, -0.15065284,  0.35949183, -0.32943895, -0.34228748,\n",
       "       -0.13397422,  0.1020711 , -0.23231083,  0.12691572,  0.24661215,\n",
       "       -0.22266667,  0.02982853,  0.03184864, -0.34999555, -0.34347755], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['satan']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
