{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import numpy\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "dataset = fetch_20newsgroups(subset='all')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "X_tfidf = tfidf.fit_transform(dataset.data)\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "n_comp = 10\n",
    "svd = TruncatedSVD(n_components=n_comp)\n",
    "X_svd = svd.fit_transform(X_tfidf)\n",
    "\n",
    "y = dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_svd, y, test_size = 0.3, random_state = 1)\n",
    "\n",
    "N_train, _ = X_train.shape \n",
    "N_test,  _ = X_test.shape \n",
    "\n",
    "print (N_train, N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.36014251061249242, 0.5452776795189247)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "knn = KNeighborsClassifier().fit(X_train, y_train)\n",
    "\n",
    "y_train_predict = knn.predict(X_train)\n",
    "y_test_predict = knn.predict(X_test)\n",
    "\n",
    "err_train = numpy.mean(y_train != y_train_predict)\n",
    "err_test  = numpy.mean(y_test  != y_test_predict)\n",
    "\n",
    "print (err_train, err_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.40      0.52      0.45       251\n",
      "          1       0.21      0.38      0.27       289\n",
      "          2       0.37      0.38      0.38       318\n",
      "          3       0.41      0.40      0.40       304\n",
      "          4       0.32      0.31      0.31       278\n",
      "          5       0.33      0.39      0.36       290\n",
      "          6       0.47      0.49      0.48       300\n",
      "          7       0.31      0.34      0.32       311\n",
      "          8       0.36      0.38      0.37       297\n",
      "          9       0.50      0.55      0.52       283\n",
      "         10       0.74      0.62      0.68       314\n",
      "         11       0.89      0.75      0.81       312\n",
      "         12       0.28      0.22      0.24       287\n",
      "         13       0.34      0.35      0.35       297\n",
      "         14       0.69      0.51      0.59       313\n",
      "         15       0.59      0.65      0.62       283\n",
      "         16       0.58      0.53      0.55       267\n",
      "         17       0.81      0.72      0.76       259\n",
      "         18       0.47      0.31      0.37       234\n",
      "         19       0.37      0.17      0.23       167\n",
      "\n",
      "avg / total       0.48      0.45      0.46      5654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (classification_report(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Popular words in category #', 1, array([u'for', u'you', u'it', u'is', u'that', u'in', u'and', u'of', u'to'], \n",
      "      dtype='<U180'))\n",
      "('Popular words in category #', 2, array([u'they', u'we', u'were', u'his', u'was', u'that', u'god', u'he',\n",
      "       u'of'], \n",
      "      dtype='<U180'))\n",
      "('Popular words in category #', 3, array([u'team', u'armenians', u'drive', u'and', u'on', u'armenian',\n",
      "       u'game', u'of', u'was'], \n",
      "      dtype='<U180'))\n",
      "('Popular words in category #', 4, array([u'writes', u'article', u'team', u'university', u'in', u'game',\n",
      "       u'his', u'was', u'he'], \n",
      "      dtype='<U180'))\n",
      "('Popular words in category #', 5, array([u'team', u'him', u'my', u'was', u'it', u'game', u'drive', u'scsi',\n",
      "       u'his'], \n",
      "      dtype='<U180'))\n",
      "('Popular words in category #', 6, array([u'writes', u're', u'government', u'key', u'clipper', u'netcom',\n",
      "       u'stratus', u'they', u'you'], \n",
      "      dtype='<U180'))\n",
      "('Popular words in category #', 7, array([u'kent', u'his', u'netcom', u'uk', u'stratus', u'jesus', u'sandvik',\n",
      "       u'he', u'god'], \n",
      "      dtype='<U180'))\n",
      "('Popular words in category #', 8, array([u'escrow', u'digex', u'access', u'is', u'be', u'he', u'chip',\n",
      "       u'encryption', u'clipper'], \n",
      "      dtype='<U180'))\n",
      "('Popular words in category #', 9, array([u'cwru', u'acs', u'cleveland', u'magnus', u'ide', u'state', u'edu',\n",
      "       u'drive', u'ohio'], \n",
      "      dtype='<U180'))\n",
      "('Popular words in category #', 10, array([u'that', u'gov', u'space', u'toronto', u'scsi', u'it', u'nasa',\n",
      "       u'henry', u'is'], \n",
      "      dtype='<U180'))\n"
     ]
    }
   ],
   "source": [
    "for i_t,i in enumerate(svd.components_,1):\n",
    "    ind = numpy.argsort(i)\n",
    "    print (\"Popular words in category #\",i_t,numpy.asarray(tfidf.get_feature_names())[ind[-10:-1]][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_tokenized = [nltk.word_tokenize(text) for text in dataset.data]\n",
    "\n",
    "texts = []\n",
    "for text in dataset_tokenized:\n",
    "    lemms = []\n",
    "    for word in text:\n",
    "        if word not in string.punctuation:\n",
    "            lemms.append(word.lower())\n",
    "    texts.append(lemms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18846, 158, 133)\n"
     ]
    }
   ],
   "source": [
    "print (len(texts), len(texts[0]), len(texts[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'house', 0.5042642951011658),\n",
       " (u'called', 0.48002660274505615),\n",
       " (u'holes', 0.47237879037857056),\n",
       " (u'helios.usq.edu.au', 0.45455724000930786),\n",
       " (u'gang', 0.43754374980926514),\n",
       " (u'filled', 0.4052257835865021),\n",
       " (u'cult', 0.40019476413726807),\n",
       " (u'chatnam', 0.38969773054122925),\n",
       " (u'inside', 0.36760005354881287),\n",
       " (u'burning', 0.35901063680648804)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(texts)\n",
    "model.most_similar(positive=['black', 'white'], negative=['red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'power'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"Earth Mars Jupiter power\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58408312229729997"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('black', 'red')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
