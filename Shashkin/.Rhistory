rbind_all %>%
mutate(wikitext = unlist(wikitext, use.names = FALSE))
dataset$wikitext[3] %>%
str_match_all(pattern = "\\[\\[\\Image:[:print:]+\\]{2,4}")
dataset$wikitext[2] %>%
str_match_all(pattern = "\\[\\[\\Image:[:print:]+\\]{2,4}")
dataset$wikitext[3] %>%
str_match_all(pattern = "\\[\\[\\Image:[:print:]+\\]{2,4}")
dataset$wikitext[4] %>%
str_match_all(pattern = "\\[\\[\\Image:[:print:]+\\]{2,4}")
dataset$wikitext[5] %>%
str_match_all(pattern = "\\[\\[\\Image:[:print:]+\\]{2,4}")
dataset$wikitext[6] %>%
str_match_all(pattern = "\\[\\[\\Image:[:print:]+\\]{2,4}")
dataset$wikitext[7] %>%
str_match_all(pattern = "\\[\\[\\Image:[:print:]+\\]{2,4}")
dataset$wikitext[8] %>%
str_match_all(pattern = "\\[\\[\\Image:[:print:]+\\]{2,4}")
dataset$wikitext[9] %>%
str_match_all(pattern = "\\[\\[\\Image:[:print:]+\\]{2,4}")
dataset$wikitext[10] %>%
str_match_all(pattern = "\\[\\[\\Image:[:print:]+\\]{2,4}")
dataset$wikitext[10]
dataset$wikitext[10] %>%
str_match_all(pattern = "\\[\\[\\(Image)|(File):[:print:]+\\]{2,4}")
dataset$wikitext[10] %>%
str_match_all(pattern = "\\[\\[\\[Image|File]:[:print:]+\\]{2,4}")
dataset$wikitext[10] %>%
str_match_all(pattern = "\\[\\[\\[Image:|File:][:print:]+\\]{2,4}")
dataset$wikitext[10] %>%
str_match_all(pattern = "\\[\\[\\[(Image:)|(File:)][:print:]+\\]{2,4}")
?regexp
dataset$wikitext[10] %>%
str_match_all(pattern = "\\[\\[File:[:print:]+\\]{2,4}")
dataset$wikitext[10] %>%
str_match_all(pattern = "\\[\\[[[File]|[Image]]:[:print:]+\\]{2,4}")
dataset$wikitext[10] %>%
str_match_all(pattern = "\\[\\[[File|Image]:[:print:]+\\]{2,4}")
dataset$wikitext[10] %>%
str_match_all(pattern = "\\[\\[(File)|(Image):[:print:]+\\]{2,4}")
dataset$wikitext[10] %>%
str_extract_all(pattern = "\\[\\[(File)|(Image):[:print:]+\\]{2,4}")
dataset$wikitext[10] %>%
str_extract_all(pattern = "\\[\\[(File)|(Image)\\:[:print:]+\\]{2,4}")
dataset$wikitext[10] %>%
str_extract_all(pattern = "\\[\\[File|Image\\:[:print:]+\\]{2,4}")
dataset$wikitext[10] %>%
str_extract_all(pattern = "\\[\\[(File|Image)\\:[:print:]+\\]{2,4}")
dataset$wikitext[10] %>%
str_extract_all(pattern = "\\[\\[(File|Image)\\:[:print:]+\\]\\]")
dataset$wikitext[10]
dataset$wikitext[10] %>%
str_extract_all(pattern = "\\[\\[File:")
dataset$wikitext[10] %>%
str_extract_all(pattern = "\\[\\[File:*\\]\\]")
dataset$wikitext[10] %>%
str_extract_all(pattern = "\\[\\[File:[:print:]*\\]\\]")
dataset$wikitext[10] %>%
str_extract_all(pattern = "\\[\\[File:[^(\\[|\\])]*\\]\\]")
dataset$wikitext[10] %>%
str_extract_all(pattern = "\\[\\[File:[^\\]]+   \\]\\]")
dataset$wikitext[10] %>%
str_extract_all(pattern = "\\[\\[File:[^[\\]]]+   \\]\\]")
a <- random_page(language = "en", project = "wikinews", as_wikitext = FALSE, namespaces = "0")
a
dataset$wikitext[10]
dataset$wikitext[10] %>%
str_match_all(pattern = "\\[\\[\\Category:([:print:]+)\\]\\]")
dataset$wikitext[10] %>% str_extract_all(pattern = "\\{\\{[:print:]+\\}\\}")
dataset$wikitext[9] %>% str_extract_all(pattern = "\\{\\{[:print:]+\\}\\}")
dataset$wikitext[9]
dataset$wikitext[9] %>% str_extract_all(pattern = "\\{\\{[:print:]+\\}\\}")
dataset$wikitext[10] %>%
str_extract_all(pattern = "\\{{2}[^{}]+\\}{2}")
dataset$wikitext[10] %>%
str_extract_all(pattern = "\\{{2}source[^{}]+\\}{2}")
dataset$wikitext[10] %>%
str_extract_all(pattern = "\\{{2}(source|date)[^{}]+\\}{2}")
dataset$wikitext[10] %>%
str_extract_all(pattern = "\\{{2}(source|date|publish|archive)[^{}]*\\}{2}")
dataset$wikitext[10] %>%
str_extract_all(pattern = "\\{{2}(source|date)[^{}]+\\}{2}")
dataset$wikitext[10] %>%
str_extract_all(pattern = "\\{{2}(source|date)[^}]+\\}{2}")
dataset$wikitext[10] %>%
str_extract_all(pattern = "\\[{2}(File|Image)[^[]]+\\]{2}")
dataset$wikitext[10] %>%
str_extract_all(pattern = "\\[{2}(File|Image):[^\\[]+\\]{2}")
dataset$wikitext[10] %>%
str_extract_all(pattern = "\\[{2}(File|Image):[^\\[\\]]+\\]{2}")
dataset$wikitext[10] %>%
str_replace_all(pattern = c("\\[{2}(File|Image):[^\\[\\]]+\\]{2}",
"\\{{2}(source|date)[^{}]+\\}{2}",fixed("{{publish}}"),
fixed("{{archive}}")))
dataset$wikitext[10] %>%
str_replace_all(pattern = c("\\[{2}(File|Image):[^\\[\\]]+\\]{2}",
"\\{{2}(source|date)[^{}]+\\}{2}",fixed("{{publish}}"),
fixed("{{archive}}")), "")
dataset$wikitext[10] %>%
str_replace_all("\\[{2}(File|Image):[^\\[\\]]+\\]{2}", "")
dataset$wikitext[10] %>%
str_replace_all(c(fixed("{{publish}}"),fixed("{{archive}}")), "")
dataset$wikitext[10] %>%
str_replace_all(fixed("{{publish}}", "")
dataset$wikitext[10] %>%
str_replace_all(fixed("{{publish}}"), "")
dataset$wikitext[10] %>%
str_replace_all(c(fixed("{{publish}}"), fixed("{{archive}}")), "")
?str_replace_all
dataset$wikitext[10] %>%
str_replace_all(c(fixed("{{publish}}"), fixed("{{archive}}")), c("",""))
dataset$wikitext[10] %>%
str_replace_all(c("\\[{2}(File|Image):[^\\[\\]]+\\]{2}",
"\\{{2}(source|date)[^{}]+\\}{2}"), "")
dataset$wikitext[10] %>%
str_replace_all(c("\\[{2}(File|Image|Category):[^\\[\\]]+\\]{2}",
"\\{{2}(source|date|publish|archive)[^{}]*\\}{2}"), "")
dataset$wikitext[10] %>%
str_replace_all("\\[{2}(File|Image|Category):[^\\[\\]]+\\]{2}","") %>%
str_replace_all("\\{{2}(source|date|publish|archive)[^{}]*\\}{2}","")
dataset$wikitext[10] %>%
str_match_all(pattern = "\\[\\[\\Category:([:print:]+)\\]\\]")
dataset$wikitext[8:10] %>%
str_match_all(pattern = "\\[\\[\\Category:([:print:]+)\\]\\]")
dataset$wikitext[8:10] %>%
str_match_all(pattern = "\\[\\[\\Category:([:print:]+)\\]\\]") %>%
sapply(. %>% paste(.[,2], sep = ","))
dataset$wikitext[8:10] %>%
str_match_all(pattern = "\\[\\[\\Category:([:print:]+)\\]\\]") %>%
sapply(. %>% {paste(.[,2], sep = ",")})
dataset$wikitext[8:10] %>%
str_match_all(pattern = "\\[\\[\\Category:([:print:]+)\\]\\]") %>%
sapply(. %>% {paste(.[,2], collapse = ",")})
?categories_in_page
dataset <- replicate(10, expr = random_page(language = "en", project = "wikinews", as_wikitext = TRUE, namespaces = "0") %$%
parse %>% as_data_frame, simplify = FALSE) %>%
rbind_all %>%
mutate(wikitext = unlist(wikitext, use.names = FALSE),
categories = str_match_all(wikitext, pattern = "\\[\\[\\Category:([:print:]+)\\]\\]") %>%
sapply(. %>% {paste(.[,2], collapse = ", ")}))
dataset
dataset %>% View
dataset$wikitext %<>% str_replace_all("\\[{2}(File|Image|Category):[^\\[\\]]+\\]{2}","")
dataset$wikitext %<>% str_replace_all("\\{{2}(source|date|publish|archive)[^{}]*\\}{2}","")
dataset$wikitext[1]
dataset$wikitext %<>% str_replace_all("\\{{2}(source|date|publish|archive|wikinews|haveyoursay)[^{}]*\\}{2}","")
dataset$wikitext[1]
dataset$wikitext[1] %>% str_extract_all("\\[{2}(File|Image|Category):[^\\[\\]]+\\]{2}","")
dataset <- replicate(10, expr = random_page(language = "en", project = "wikinews", as_wikitext = TRUE, namespaces = "0") %$%
parse %>% as_data_frame, simplify = FALSE) %>%
rbind_all %>%
mutate(wikitext = unlist(wikitext, use.names = FALSE),
categories = str_match_all(wikitext, pattern = "\\[\\[\\Category:([:print:]+)\\]\\]") %>%
sapply(. %>% {paste(.[,2], collapse = ", ")}))
dataset$wikitext[1] %>% str_extract_all("\\[{2}(File|Image|Category):[^\\[\\]]+\\]{2}","")
dataset$wikitext[1]
dataset$wikitext[1] %>% str_extract_all("\\[{2}(File|Image|Category):[^\\[\\]]+\\]{2}")
dataset$wikitext[1] %>% str_replace_all("\\[{2}(File|Image|Category):[^\\[\\]]+\\]{2}"," ")
dataset$wikitext %<>% str_replace_all("\\[{2}(File|Image|Category):[^\\[\\]]+\\]{2}"," ")
dataset$wikitext[1] %>% str_extract_all("\\{{2}(source|date|publish|archive|wikinews|haveyoursay)[^{}]*\\}{2}")
dataset$wikitext[2] %>% str_extract_all("\\{{2}(source|date|publish|archive|wikinews|haveyoursay)[^{}]*\\}{2}")
dataset$wikitext[3] %>% str_extract_all("\\{{2}(source|date|publish|archive|wikinews|haveyoursay)[^{}]*\\}{2}")
dataset$wikitext %<>% str_replace_all("\\[{2}(File|Image|Category):[^\\[\\]]+\\]{2}"," ")
dataset$wikitext %<>% str_replace_all("\\{{2}(source|date|publish|archive|wikinews|haveyoursay)[^{}]*\\}{2}"," ")
dataset$wikitext[1]
dataset$wikitext[2]
dataset$wikitext[2] %>% str_extract_all("== Related News ==.?*")
dataset$wikitext[2] %>% str_extract_all("== Related News ==")
dataset$wikitext[2] %>% str_locate("== Related News ==")
dataset$wikitext[2] %>% str_locate(c("== Related News ==","== Sources =="))
dataset$wikitext[2] %>% str_locate(c("== Related News ==","== Sources =="))$start - 1
dataset$wikitext[2] %>% str_locate(c("== Related News ==","== Sources ==")) %$% {start - 1}
dataset$wikitext[2] %>% str_locate(c("== Related News ==","== Sources ==")) %>% {.[,"start"] - 1}
dataset$wikitext[2] %>% nchar
dataset$wikitext %>% str_locate(c("== Related News ==","== Sources =="))
min(dataset$wikitext %>% str_locate(c("== Related News ==","== Sources ==")) %>% {.[,"start"] - 1},
dataset$wikitext %>% nchar, na.rm = TRUE)
dataset$wikitext[2] %>% str_extract("== Related News ==[:print:]*")
dataset$wikitext[2]
dataset$wikitext[2] %>% str_extract("== Related News ==.*")
dataset$wikitext[2] %>% str_extract("== Related News ==.+")
dataset$wikitext[2] %>% str_extract("== Related News ==.*")
dataset$wikitext[2] %>% min(str_locate_all(.,c("== Related News ==", "== Sources ==")), nchar(.))
dataset$wikitext[2] %>% str_locate_all(c("== Related News ==", "== Sources =="))
dataset$wikitext[2] %>% str_locate(c("== Related News ==", "== Sources =="))
dataset$wikitext[2] %>% min(nchar(.), str_locate(c("== Related News ==", "== Sources =="), na.rm = TRUE))
?regexp
dataset$wikitext %<>% str_replace_all("[^[:print:]]"," ")
dataset$wikitext[2]
dataset$wikitext[2] %>% str_locate("[:print:]*(== Related News ==|== Sources ==)")
dataset$wikitext[2] %>% str_extract("[:print:]*(== Related News ==|== Sources ==)")
dataset$wikitext[2] %>% str_extract("(== Related News ==|== Sources ==)[:print:]*")
dataset$wikitext[2] %>% str_extract("\\<[^<>]*\\>")
dataset$wikitext[2] %>% str_extract_all("\\<[^<>]*\\>")
?trimws
require(WikipediR)
require(dplyr)
require(stringr)
dataset <- replicate(10, expr = random_page(language = "en", project = "wikinews", as_wikitext = TRUE, namespaces = "0") %$%
parse %>% as_data_frame, simplify = FALSE) %>%
rbind_all %>%
mutate(wikitext = unlist(wikitext, use.names = FALSE) %>% str_replace_all("[^[:print:]]"," "),
categories = str_match_all(wikitext, pattern = "\\[\\[\\Category:([:print:]+)\\]\\]") %>%
sapply(. %>% {paste(.[,2], collapse = ", ")}))
dataset$wikitext %<>%
str_replace_all("\\[{2}(File|Image|Category):[^\\[\\]]+\\]{2}", " ") %>%
str_replace_all("\\{{2}(source|date|publish|archive|wikinews|haveyoursay|Audio)[^{}]*\\}{2}", " ") %>%
str_replace_all("(== Related News ==|== Sources ==)[:print:]*", " ") %>%
str_replace_all("\\<[^<>]*\\>", " ") %>%
str_replace_all("[:space:]+", " ")
dataset %>% View
dataset$wikitext[1]
dataset$wikitext[1] %>% str_replace_all("\\[{2}(File|Image|Category):[^\\[\\]]+\\]{2}", " ")
dataset$wikitext[1] %>% str_extract_all("\\[{2}(File|Image|Category):[^\\[\\]]+\\]{2}", " ")
dataset$wikitext[1] %>% str_extract_all("\\[{2}(File|Image):[^\\[\\]]+\\]{2}")
dataset$wikitext[1] %>% str_extract_all("\\[{2}File:[^\\[\\]]+\\]{2}")
dataset$wikitext[1] %>% str_extract_all("\\[{2}File:")
dataset$wikitext[1] %>% str_extract_all("\\[{2}File:[^\\[|\\]]+\\]{2}")
dataset$wikitext[1] %>% str_extract_all("\\[{2}File:[^\\]]+\\]{2}")
dataset$wikitext[1] %>% str_extract_all("\\[{2}File:[^(\\]|\\[)]]+\\]{2}")
dataset$wikitext[1] %>% str_extract_all("\\[{2}File:[^\\]|\\[]]+\\]{2}")
dataset$wikitext[1] %>% str_extract_all("\\[{2}File:[^\\]]+\\]{2}")
dataset$wikitext[1] %>% str_extract_all("\\[{2}File:^(\\]|\\[)+\\]{2}")
dataset$wikitext[1] %>% str_extract_all("\\[{2}File:[^(\\]|\\[)]+\\]{2}")
dataset <- replicate(10, expr = random_page(language = "en", project = "wikinews", as_wikitext = TRUE, namespaces = "0") %$%
parse %>% as_data_frame, simplify = FALSE) %>%
rbind_all
dataset %<>% mutate(wikitext = unlist(wikitext, use.names = FALSE) %>% str_replace_all("[^[:print:]]"," "))
str_match_all(dataset$wikitext, pattern = "\\[\\[\\Category:([:print:]+)\\]\\]") %>%
sapply(. %>% {paste(.[,2], collapse = ", ")})
str_match_all(dataset$wikitext, pattern = "\\[\\[\\Category:([^\\[\\]])\\]\\]") %>%
sapply(. %>% {paste(.[,2], collapse = ", ")})
str_match_all(dataset$wikitext, pattern = "\\[\\[\\Category:([^[]])\\]\\]") %>%
sapply(. %>% {paste(.[,2], collapse = ", ")})
?regexp
a <- random_page(language = "en", project = "wikinews", as_wikitext = TRUE, namespaces = "0") %$%
parse %>% as_data_frame
a$wikitext$`*`
a <- a$wikitext$`*`
a
a %>% str_replace_all("[^[:print:]]"," ")
a %<>% str_replace_all("[^[:print:]]"," ")
a %>% str_match_all("\\[\\[Category:[^\\]]*\\]\\]")
a %>% str_match_all("Category:([^\\]]*)\\]\\]")
a %>% str_match_all("Category:([^\\]]*)")
a %>% str_match_all("Category:([^\\]]*)") %>% .[,2]
a %>% str_match_all("Category:([^\\]]*)") %>% .[[1]][,2]
a %>% str_match_all("Category:([^\\]]*)") %>% {.[[1]][,2]}
a %>% str_match_all("Category:([^\\]]*)") %>% {.[[1]][,2]} %>% paste(sep = ", ")
a %>% str_match_all("Category:([^\\]]*)") %>% {.[[1]][,2]} %>% paste(collapse = ", ")
a %>% str_extract_all("\\[{2}(File|Image|Category):[^\\[\\]]+\\]{2}")
a %>% str_replace_all("\\[{2}(File|Image|Category):[^\\[\\]]+\\]{2}"," ")
a
a %>% str_extract_all("\\{{2}(source|date|publish|archive|wikinews|haveyoursay|Audio)[^{}]*\\}{2}")
a %>% str_extract_all("(== Related News ==|== Sources ==)[:print:]*")
a %>% str_replace_all("\\[{2}(File|Image|Category):[^\\[\\]]+\\]{2}"," ") %>%
str_replace_all("\\{{2}(source|date|publish|archive|wikinews|haveyoursay|Audio)[^{}]*\\}{2}"," ") %>%
str_replace_all("(== Related News ==|== Sources ==)[:print:]*", " ") %>%
str_replace_all("\\<[^<>]*\\>", " ") %>%
str_replace_all("[:space:]+", " ")
a <- random_page(language = "en", project = "wikinews", as_wikitext = TRUE, namespaces = "0") %$%
parse %>% as_data_frame
a <- a$wikitext$`*`
a %<>% str_replace_all("[^[:print:]]"," ")
categories <- a %>% str_match_all("Category:([^\\]]*)") %>% {.[[1]][,2]} %>% paste(collapse = ", ")
a %>% str_replace_all("\\[{2}(File|Image|Category):[^\\[\\]]+\\]{2}"," ") %>%
str_replace_all("\\{{2}(source|date|publish|archive|wikinews|haveyoursay|Audio)[^{}]*\\}{2}"," ") %>%
str_replace_all("== (Related News|Sources)[:print:]*", " ") %>%
str_replace_all("\\<[^<>]*\\>", " ") %>%
str_replace_all("[:space:]+", " ")
dataset <- replicate(3, expr = random_page(language = "en", project = "wikinews", as_wikitext = TRUE, namespaces = "0") %$%
parse %>% as_data_frame, simplify = FALSE) %>%
rbind_all %>%
mutate(wikitext = unlist(wikitext, use.names = FALSE) %>% str_replace_all("[^[:print:]]"," "))
dataset$wikitext
dataset$wikitext %>% str_match_all("Category:([^\\]]*)")
dataset$wikitext %>% str_match_all("Category:([^\\]]*)") %>% sapply(. %>% {paste(.[,2], collapse = ", ")})
dataset <- replicate(3, expr = random_page(language = "en", project = "wikinews", as_wikitext = TRUE, namespaces = "0") %$%
parse %>% as_data_frame, simplify = FALSE) %>%
rbind_all %>%
mutate(wikitext = unlist(wikitext, use.names = FALSE) %>% str_replace_all("[^[:print:]]"," "),
categories = str_match_all(wikitext, "Category:([^\\]]*)") %>%
sapply(. %>% {paste(.[,2], collapse = ", ")}))
dataset$categories
a <- dataset$wikitext %>% str_replace_all("\\[{2}(File|Image|Category):[^\\[\\]]+\\]{2}"," ")
a
a <- dataset$wikitext %>% str_replace_all("\\[{2}(File|Image|Category):[^\\[\\]]+\\]{2}"," ") %>%
str_replace_all("\\{{2}(source|date|publish|Publish|archive|Archive|wikinews|haveyoursay|Audio)[^{}]*\\}{2}"," ") %>%
str_replace_all("== (Related News|Sources)[:print:]*", " ") %>%
str_replace_all("\\<[^<>]*\\>", " ") %>%
str_replace_all("[:space:]+", " ")
a[1]
dataset$wikitext[1] %>% str_replace_all("\\[{2}(File|Image|Category):[^\\[\\]]+\\]{2}"," ") %>%
str_replace_all("\\{{2}(source|date|publish|Publish|archive|Archive|wikinews|haveyoursay|Audio)[^{}]*\\}{2}"," ") %>%
str_replace_all("==[:space:]*(Related News|Sources)[:print:]*", " ") %>%
str_replace_all("\\<[^<>]*\\>", " ") %>%
str_replace_all("[:space:]+", " ")
dataset$wikitext[2] %>% str_replace_all("\\[{2}(File|Image|Category):[^\\[\\]]+\\]{2}"," ") %>%
str_replace_all("\\{{2}(source|date|publish|Publish|archive|Archive|wikinews|haveyoursay|Audio|image)[^{}]*\\}{2}"," ") %>%
str_replace_all("==[:space:]*(Related News|Sources)[:print:]*", " ") %>%
str_replace_all("\\<[^<>]*\\>", " ") %>%
str_replace_all("[:space:]+", " ")
dataset$wikitext[1] %>% str_replace_all("\\[{2}(File|Image|Category):[^\\[\\]]+\\]{2}"," ")
dataset$wikitext[1] %>% str_extract_all("\\[{2}(File|Image|Category):[^\\[\\]]+\\]{2}")
dataset$wikitext[1] %>% str_extract_all("\\[{2}(File|Image|Category):[^\\]{2}]+\\]{2}")
dataset$wikitext[1] %>% str_extract_all("\\[{2}(File|Image|Category):[^\\]\\]]+\\]{2}")
dataset <- replicate(5, expr = random_page(language = "en", project = "wikinews", as_wikitext = TRUE, namespaces = "0") %$%
parse %>% as_data_frame, simplify = FALSE) %>%
rbind_all %>%
mutate(wikitext = unlist(wikitext, use.names = FALSE) %>% str_replace_all("[^[:print:]]"," "),
categories = str_match_all(wikitext, "Category:([^\\]]*)") %>%
sapply(. %>% {paste(.[,2], collapse = ", ")}))
dataset$wikitext[1]
dataset$wikitext %>% str_replace_all("==[:space:]*(Related News|Sources)[:print:]*", " ")
dataset$wikitext %<>% str_replace_all("==[:space:]*(Related News|Sources)[:print:]*", " ")
dataset$wikitext
dataset$wikitext[1]
dataset$wikitext[2]
dataset$wikitext[3]
dataset$wikitext[4]
system.time(
dataset <- replicate(50, expr = random_page(language = "en", project = "wikinews", as_wikitext = TRUE, namespaces = "0") %$%
parse %>% as_data_frame, simplify = FALSE) %>%
rbind_all %>%
mutate(wikitext = unlist(wikitext, use.names = FALSE) %>% str_replace_all("[^[:print:]]"," "),
categories = str_match_all(wikitext, "Category:([^\\]]*)") %>%
sapply(. %>% {paste(.[,2], collapse = ", ")}))
)
334/50
10000 * 6 / 60
10000 * 6 / 60 / 60
system.time(a <- replicate(4, expr = random_page(language = "en", project = "wikinews", as_wikitext = TRUE, namespaces = "0") %$%
parse %>% as_data_frame, simplify = FALSE)
)
require(parallel)
?mclapply
system.time(
a <- mclapply(1:4, replicate(4, expr = random_page(language = "en", project = "wikinews", as_wikitext = TRUE, namespaces = "0") %$%
parse %>% as_data_frame)
)
do.call(sqrt, 2)
do.call(sqrt, list(2))
system.time(
a <- mclapply(1:4, function(...) random_page(language = "en", project = "wikinews", as_wikitext = TRUE, namespaces = "0") %$%
parse %>% as_data_frame, mc.cores = 4)
)
a
require(parallelMap)
parallelStartMulticore(4)
system.time(
a <- parallelMap(1:4, function(...) random_page(language = "en", project = "wikinews", as_wikitext = TRUE, namespaces = "0") %$%
parse %>% as_data_frame, mc.cores = 4)
)
system.time(
a <- parallelMap(1:4, fun = function(...) random_page(language = "en", project = "wikinews", as_wikitext = TRUE, namespaces = "0") %$%
parse %>% as_data_frame, mc.cores = 4)
)
detach("package:parallel", unload=TRUE)
require(parallelMap)
parallelStartMulticore(4)
system.time(
a <- parallelMap(1:4, fun = function(...) random_page(language = "en", project = "wikinews", as_wikitext = TRUE, namespaces = "0") %$%
parse %>% as_data_frame)
)
parallelLibrary("WikipediR")
system.time(
a <- parallelMap(1:4, fun = function(...) random_page(language = "en", project = "wikinews", as_wikitext = TRUE, namespaces = "0") %$%
parse %>% as_data_frame)
)
require(WikipediR)
require(dplyr)
require(stringr)
dataset <- replicate(10, random_page(language = "en",
project = "wikinews",
as_wikitext = TRUE,
namespaces = "0") %$% parse %>% as_data_frame,
simplify = FALSE) %>%
rbind_all %>%
mutate(wikitext = unlist(wikitext, use.names = FALSE) %>% str_replace_all("[^[:print:]]"," "),
categories = str_match_all(wikitext, "Category:([^\\]]*)") %>%
sapply(. %>% {paste(.[,2], collapse = ", ")}))
вфефыуе
dataset
dataset %>% View
sapply(c("magrittr","quanteda","slam"), require, character.only = TRUE)
setwd("~/15-MAG-PMI/Shashkin/")
corpus <- readRDS("20newsgroups.RDS") +
corpus("Computer science is the scientific and practical approach to computation and its applications. It is the systematic study of the feasibility, structure, expression, and mechanization of the methodical procedures (or algorithms) that underlie the acquisition, representation, processing, storage, communication of, and access to information. An alternate, more succinct definition of computer science is the study of automating algorithmic processes that scale. A computer scientist specializes in the theory of computation and the design of computational systems.[1]
Its fields can be divided into a variety of theoretical and practical disciplines. Some fields, such as computational complexity theory (which explores the fundamental properties of computational and intractable problems), are highly abstract, while fields such as computer graphics emphasize real-world visual applications. Still other fields focus on challenges in implementing computation. For example, programming language theory considers various approaches to the description of computation, while the study of computer programming itself investigates various aspects of the use of programming language and complex systems. Human–computer interaction considers the challenges in making computers and computations useful, usable, and universally accessible to humans.")
dtm <- dfm(corpus, stem = TRUE, toLower = TRUE, removeNumbers = TRUE, removePunct = TRUE, language = "english") %>%
trim(minDoc = 10)
dtm <- dfm(corpus, stem = TRUE, toLower = TRUE, removeNumbers = TRUE, removePunct = TRUE, language = "english") %>%
trim(minDoc = 5)
sparse_cosine <- function(x){
sq_cs <- col_sums(x^2)
crossprod_simple_triplet_matrix(x)/(sqrt(sq_cs %*% t(sq_cs)))
}
sim_cosine <- dtm %>% weight("tfidf") %>% convert("tm") %>% t %>% sparse_cosine
bm25 <- function(dtm, query, k = 1.5, b = 0.5, gamma = 1) {
f <- dtm[,which(as.vector(dtm[query,]) > 0)]
n <- row_sums(dtm) %>% {k * (1 - b + b * . / mean(.))} %>% as.vector
res <- f * (k + 1) /
(colapply_simple_triplet_matrix(f, FUN = . %>% `+`(n)) %>% rbind_list %>% as.simple_triplet_matrix)
res$v %<>% `+`(gamma)
idf <- col_sums(f > 0) + 0.5 %>% {log((dtm$nrow - .)/.)}
rowapply_simple_triplet_matrix(res, FUN = . %>% `*`(idf)) %>% sapply(sum, USE.NAMES = FALSE)
}
bm_sim <- bm25(dtm %>% tf %>% convert("tm"), ndoc(corpus))
require(dplyr)
bm_sim <- bm25(dtm %>% tf %>% convert("tm"), ndoc(corpus))
corpus$documents$texts[order(dist_cosine[ndoc(corpus),], decreasing = TRUE)[1:5]]
cos_sim <- dtm %>% weight("tfidf") %>% convert("tm") %>% t %>% sparse_cosine
corpus$documents$texts[order(cos_sim[ndoc(corpus),], decreasing = TRUE)[1:5]]
corpus$documents$texts[order(cos_sim[ndoc(corpus),], decreasing = TRUE)[1]]
corpus$documents$texts[order(cos_sim[ndoc(corpus),], decreasing = TRUE)[2]]
corpus$documents$texts[order(cos_sim[ndoc(corpus),], decreasing = TRUE)[3]]
corpus$documents$texts[order(cos_sim[ndoc(corpus),], decreasing = TRUE)[4]]
corpus$documents$texts[order(bm_sim, decreasing = TRUE)[1]]
which.max(bm_sim)
which.min(bm_sim)
sum(bm_sim < bm_sim[ndoc(corpus)])
sum(bm_sim > bm_sim[ndoc(corpus)])
corpus$documents$texts[order(bm_sim, decreasing = TRUE)[1]]
corpus$documents$texts[order(bm_sim, decreasing = TRUE)[2]]
corpus$documents$texts[order(bm_sim, decreasing = TRUE)[3]]
corpus$documents$texts[order(bm_sim, decreasing = TRUE)[4]]
bm25 <- function(dtm, query, k = 1.5, b = 0.5, gamma = 0) {
f <- dtm[,which(as.vector(dtm[query,]) > 0)]
n <- row_sums(dtm) %>% {k * (1 - b + b * . / mean(.))} %>% as.vector
res <- f * (k + 1) /
(colapply_simple_triplet_matrix(f, FUN = . %>% `+`(n)) %>% rbind_list %>% as.simple_triplet_matrix)
res$v %<>% `+`(gamma)
idf <- col_sums(f > 0) + 0.5 %>% {log((dtm$nrow - .)/.)}
rowapply_simple_triplet_matrix(res, FUN = . %>% `*`(idf)) %>% sapply(sum, USE.NAMES = FALSE)
}
bm_sim <- bm25(dtm %>% tf %>% convert("tm"), ndoc(corpus))
corpus$documents$texts[order(bm_sim, decreasing = TRUE)[1:5]]
corpus$documents$texts[order(bm_sim, decreasing = TRUE)[1]]
corpus$documents$texts[order(bm_sim, decreasing = TRUE)[2]]
corpus$documents$texts[order(bm_sim, decreasing = TRUE)[3]]
bm25 <- function(dtm, query, k = 1.5, b = 0.5, gamma = 1) {
f <- dtm[,which(as.vector(dtm[query,]) > 0)]
n <- row_sums(dtm) %>% {k * (1 - b + b * . / mean(.))} %>% as.vector
res <- f * (k + 1) /
(colapply_simple_triplet_matrix(f, FUN = . %>% `+`(n)) %>% rbind_list %>% as.simple_triplet_matrix)
res$v %<>% `+`(gamma)
idf <- col_sums(f > 0) + 0.5 %>% {log((dtm$nrow - .)/.)}
rowapply_simple_triplet_matrix(res, FUN = . %>% `*`(idf)) %>% sapply(sum, USE.NAMES = FALSE)
}
query <- ndoc(corpus)
k = 1.5
b = 0.5
gamma = 1
f <- dtm[,which(as.vector(dtm[query,]) > 0)]
dim(f)
n <- row_sums(dtm) %>% {k * (1 - b + b * . / mean(.))} %>% as.vector
res <- f * (k + 1) /
(colapply_simple_triplet_matrix(f, FUN = . %>% `+`(n)) %>% rbind_list %>% as.simple_triplet_matrix)
colapply_simple_triplet_matrix(f, FUN = . %>% `+`(n)) %>% rbind_list %>% as.simple_triplet_matrix
res <- f * (k + 1)
colapply_simple_triplet_matrix(f, FUN = . %>% `+`(n)) %>% rbind_list %>% as.simple_triplet_matrix
dtm %<>% tf %>% convert("tm")
f <- dtm[,which(as.vector(dtm[query,]) > 0)]
n <- row_sums(dtm) %>% {k * (1 - b + b * . / mean(.))} %>% as.vector
res <- f * (k + 1) /
(colapply_simple_triplet_matrix(f, FUN = . %>% `+`(n)) %>% rbind_list %>% as.simple_triplet_matrix)
res$v %<>% `+`(gamma)
idf <- (col_sums(f > 0) + 0.5) %>% {log((dtm$nrow - .)/.)}
rowapply_simple_triplet_matrix(res, FUN = . %>% `*`(idf)) %>% sapply(sum, USE.NAMES = FALSE)
bm25 <- function(dtm, query, k = 1.5, b = 0.5, gamma = 1) {
f <- dtm[,which(as.vector(dtm[query,]) > 0)]
n <- row_sums(dtm) %>% {k * (1 - b + b * . / mean(.))} %>% as.vector
res <- f * (k + 1) /
(colapply_simple_triplet_matrix(f, FUN = . %>% `+`(n)) %>% rbind_list %>% as.simple_triplet_matrix)
res$v %<>% `+`(gamma)
idf <- (col_sums(f > 0) + 0.5) %>% {log((dtm$nrow - .)/.)}
rowapply_simple_triplet_matrix(res, FUN = . %>% `*`(idf)) %>% sapply(sum, USE.NAMES = FALSE)
}
bm_sim <- bm25(dtm %>% tf %>% convert("tm"), ndoc(corpus))
bm_sim <- bm25(dtm, ndoc(corpus))
corpus$documents$texts[order(bm_sim, decreasing = TRUE)[1]]
corpus$documents$texts[order(bm_sim, decreasing = TRUE)[2]]
bm25 <- function(dtm, query, k = 1.5, b = 0.5, gamma = 0) {
f <- dtm[,which(as.vector(dtm[query,]) > 0)]
n <- row_sums(dtm) %>% {k * (1 - b + b * . / mean(.))} %>% as.vector
res <- f * (k + 1) /
(colapply_simple_triplet_matrix(f, FUN = . %>% `+`(n)) %>% rbind_list %>% as.simple_triplet_matrix)
res$v %<>% `+`(gamma)
idf <- (col_sums(f > 0) + 0.5) %>% {log((dtm$nrow - .)/.)}
rowapply_simple_triplet_matrix(res, FUN = . %>% `*`(idf)) %>% sapply(sum, USE.NAMES = FALSE)
}
bm_sim <- bm25(dtm %>% tf %>% convert("tm"), ndoc(corpus))
bm_sim <- bm25(dtm, ndoc(corpus))
corpus$documents$texts[order(bm_sim, decreasing = TRUE)[1]]
corpus$documents$texts[order(bm_sim, decreasing = TRUE)[2]]
corpus$documents$texts[order(bm_sim, decreasing = TRUE)[3]]
corpus$documents$texts[order(bm_sim, decreasing = TRUE)[4]]
corpus$documents$texts[order(bm_sim, decreasing = TRUE)[5]]
sapply(c("magrittr","quanteda","slam","dplyr"), require, character.only = TRUE)
setwd("~/15-MAG-PMI/Shashkin/")
corpus <- readRDS("20newsgroups.RDS") +
corpus("Computer science is the scientific and practical approach to computation and its applications. It is the systematic study of the feasibility, structure, expression, and mechanization of the methodical procedures (or algorithms) that underlie the acquisition, representation, processing, storage, communication of, and access to information. An alternate, more succinct definition of computer science is the study of automating algorithmic processes that scale. A computer scientist specializes in the theory of computation and the design of computational systems.[1]
Its fields can be divided into a variety of theoretical and practical disciplines. Some fields, such as computational complexity theory (which explores the fundamental properties of computational and intractable problems), are highly abstract, while fields such as computer graphics emphasize real-world visual applications. Still other fields focus on challenges in implementing computation. For example, programming language theory considers various approaches to the description of computation, while the study of computer programming itself investigates various aspects of the use of programming language and complex systems. Human–computer interaction considers the challenges in making computers and computations useful, usable, and universally accessible to humans.")
dtm <- dfm(corpus, stem = TRUE, toLower = TRUE, removeNumbers = TRUE, removePunct = TRUE, language = "english") %>%
trim(minDoc = 2)
sparse_cosine <- function(x) {
sq_cs <- col_sums(x^2)
crossprod_simple_triplet_matrix(x)/(sqrt(sq_cs %*% t(sq_cs)))
}
cos_sim <- dtm %>% weight("tfidf") %>% convert("tm") %>% t %>% sparse_cosine
?colapply_simple_triplet_matrix
?dfm
