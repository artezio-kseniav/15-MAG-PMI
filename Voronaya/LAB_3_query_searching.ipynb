{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'Ksenia Voronaya'\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# it is difficult to handle all documents & categories after, so download only several\n",
    "corpus_data = fetch_20newsgroups(categories=['rec.motorcycles', 'rec.autos', 'rec.sport.hockey', 'soc.religion.christian'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of topics (4 categories):\n",
      "['rec.autos', 'rec.motorcycles', 'rec.sport.hockey', 'soc.religion.christian']\n",
      "Size of corpus is 2391 documents\n"
     ]
    }
   ],
   "source": [
    "print(\"List of topics ({} categories):\".format(len(list(corpus_data.target_names))))\n",
    "print(list(corpus_data.target_names))\n",
    "print(\"Size of corpus is {} documents\".format(len(corpus_data.data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove morphological affixes from words, leaving only the word stem\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [i for i in tokens if i not in string.punctuation]\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kvoronaya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download only the punkt corpus, use it if LookupError\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TF-IDF matrix for corpus \n",
    "corpus_tfidf = TfidfVectorizer(stop_words='english', tokenizer=tokenize)\n",
    "corpus_representation = corpus_tfidf.fit_transform(corpus_data.data)\n",
    "\n",
    "feature = corpus_tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF for each word in query string:\n",
      "team: 0.387983136288\n",
      "russia: 0.815344321601\n",
      "hockey: 0.42974727828\n"
     ]
    }
   ],
   "source": [
    "# enter a query string\n",
    "query = 'hockey in Russia, our teams'\n",
    "query_tfidf = corpus_tfidf.transform([query])\n",
    "\n",
    "print(\"TF-IDF for each word in query string:\")\n",
    "for word in query_tfidf.nonzero()[1]:\n",
    "    print(str(feature[word]) + ': {}'.format(query_tfidf[0, word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_representation_arr = corpus_representation.toarray()\n",
    "\n",
    "# no needed to have a full texts, will print only thematic for current text\n",
    "def get_text_thematic(numb):\n",
    "    thematic = corpus_data.data[numb].split(\"\\n\")[:5]\n",
    "    return \" \".join([x if 'Subject' in x else '' for x in thematic]) \n",
    "\n",
    "# to find similarity between query string and each text in corpus, \n",
    "# will print only the closest texts\n",
    "def cosine_similarity_results(query_str, text_count):\n",
    "    \n",
    "    print('The query string is \"{}\"'.format(query_str))\n",
    "    cosine_similarity_results = {}\n",
    "    tfidf_query_str = corpus_tfidf.transform([query_str])\n",
    "    tfidf_query_str = tfidf_query_str.toarray()\n",
    "    \n",
    "    for i in xrange(corpus_representation.shape[0]):\n",
    "        cosine_dist = cosine_similarity(corpus_representation_arr[i], tfidf_query_str)\n",
    "        text_thematic = get_text_thematic(i)\n",
    "        cosine_similarity_results[text_thematic]=cosine_dist\n",
    "        \n",
    "    for key, value in sorted(cosine_similarity_results.items(), reverse=True, key=lambda x:x[1])[:text_count]:\n",
    "        print('Cosine Similarity is {}, for document \"{}\"'.format(value, key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query string is \"world champions in hockey\"\n",
      "Cosine Similarity is [[ 0.29167389]], for document \"  Subject: Re: Bruins vs Canadiens:  \"\n",
      "Cosine Similarity is [[ 0.23939343]], for document \"  Subject: Keenan signs, Plus WALSH????????  \"\n",
      "Cosine Similarity is [[ 0.1535178]], for document \" Subject: Re: Leaf slump over   \"\n",
      "Cosine Similarity is [[ 0.14756857]], for document \" Subject: Re: Hockey Hell   \"\n",
      "Cosine Similarity is [[ 0.13054062]], for document \" Subject: Re: Integra GSR (really about other cars)   \"\n",
      "Cosine Similarity is [[ 0.12955367]], for document \" Subject: NHL Team Items...   \"\n",
      "Cosine Similarity is [[ 0.12814987]], for document \" Subject: Re: AHL Calder Cup Playoff preview   \"\n",
      "Cosine Similarity is [[ 0.12668325]], for document \" Subject: AHL News   \"\n",
      "Cosine Similarity is [[ 0.12211145]], for document \"Subject: Remarks by President Clinton to NCAA Division I Champion Hockey Team    \"\n",
      "Cosine Similarity is [[ 0.12204393]], for document \" Subject: Re: Hockey and the Hispanic community   \"\n",
      "Cosine Similarity is [[ 0.11181645]], for document \"  Subject:    college hockey all-star game  \"\n",
      "Cosine Similarity is [[ 0.11056291]], for document \"Subject: College Hockey All-Star Roster    \"\n",
      "Cosine Similarity is [[ 0.10650399]], for document \" Subject: Re: WC Pool B : GB win the gold   \"\n",
      "Cosine Similarity is [[ 0.10567303]], for document \"Subject: Paul Kuryia and Canadian World Team    \"\n",
      "Cosine Similarity is [[ 0.10226226]], for document \" Subject: Re: In memoriam: Dan Kelly and Danny Gallivan   \"\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity_results('world champions in hockey', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query string is \"christian religion\"\n",
      "Cosine Similarity is [[ 0.51763645]], for document \" Subject: Why religion and which religion?   \"\n",
      "Cosine Similarity is [[ 0.35333405]], for document \" Subject: Legal definition of religion   \"\n",
      "Cosine Similarity is [[ 0.35006914]], for document \" Subject: Re: Knowing God's Will   \"\n",
      "Cosine Similarity is [[ 0.29608097]], for document \" Subject: Atheist's views on Christianity (was: Re: \"Accepting Jeesus in your heart...\")   \"\n",
      "Cosine Similarity is [[ 0.22362192]], for document \" Subject: Re: Is \"Christian\" a dirty word?   \"\n",
      "Cosine Similarity is [[ 0.21061985]], for document \" Subject: Re: tuff to be a Christian?   \"\n",
      "Cosine Similarity is [[ 0.20642596]], for document \" Subject: \"Accepting Jeesus in your heart...\"   \"\n",
      "Cosine Similarity is [[ 0.19027318]], for document \" Subject: Bible Unsuitable for New Christians   \"\n",
      "Cosine Similarity is [[ 0.18107703]], for document \" Subject: Religious wars   \"\n",
      "Cosine Similarity is [[ 0.17950888]], for document \" Subject: tuff to be a Christian?   \"\n",
      "Cosine Similarity is [[ 0.16222671]], for document \" Subject: Re: Some questions from a new Christian   \"\n",
      "Cosine Similarity is [[ 0.15995328]], for document \" Subject: RFD: soc.religion.islam.ahmadiyya moderated   \"\n",
      "Cosine Similarity is [[ 0.15953514]], for document \" Subject: Christians in the Martial Arts   \"\n",
      "Cosine Similarity is [[ 0.15822325]], for document \" Subject: Questions from a newbie   \"\n",
      "Cosine Similarity is [[ 0.15693886]], for document \" Subject: Conversions   \"\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity_results('christian religion', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query string is \"the expensive autos\"\n",
      "Cosine Similarity is [[ 0.21560458]], for document \" Subject: Manual Shift Bigots   \"\n",
      "Cosine Similarity is [[ 0.19421833]], for document \" Subject: Re: SHO and SC   \"\n",
      "Cosine Similarity is [[ 0.16555126]], for document \" Subject: Re: Chrysler New Yorker LHS (was Re: Chryslers Compact LH Sedans?)   \"\n",
      "Cosine Similarity is [[ 0.16180251]], for document \" Subject: Re: Best Radar Detector - VALENTINE-1?   \"\n",
      "Cosine Similarity is [[ 0.13648251]], for document \" Subject: Heard of these South Bay shops?   \"\n",
      "Cosine Similarity is [[ 0.09857532]], for document \"Subject: apology (was Re: Did US drive on the left?)    \"\n",
      "Cosine Similarity is [[ 0.09086229]], for document \" Subject: Re: Manual Shift Bigots wanted   \"\n",
      "Cosine Similarity is [[ 0.08599015]], for document \" Subject: Re: ARCTIC WHEELS AUTO SHOW   \"\n",
      "Cosine Similarity is [[ 0.08497326]], for document \" Subject: Re: GEICO mechanical breakdown insurance   \"\n",
      "Cosine Similarity is [[ 0.08247272]], for document \" Subject: Re: Manual Shift Bigots   \"\n",
      "Cosine Similarity is [[ 0.07094527]], for document \" Subject: Re: Auto air conditioning without Freon   \"\n",
      "Cosine Similarity is [[ 0.06697243]], for document \" Subject: Re: Renting from Alamo\t   \"\n",
      "Cosine Similarity is [[ 0.06568077]], for document \" Subject: Re: Round Two   \"\n",
      "Cosine Similarity is [[ 0.06361188]], for document \" Subject: Re: hats update... patches too!   \"\n",
      "Cosine Similarity is [[ 0.06308542]], for document \" Subject: MILITECH   \"\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity_results('the expensive autos', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query string is \"the fastest motorcycles\"\n",
      "Cosine Similarity is [[ 0.16711329]], for document \" Subject: Re: Its still cold, but...   \"\n",
      "Cosine Similarity is [[ 0.16645309]], for document \" Subject: Misc./buying info. needed   \"\n",
      "Cosine Similarity is [[ 0.14652274]], for document \" Subject: Misc./Buying Info. Needed   \"\n",
      "Cosine Similarity is [[ 0.10717457]], for document \" Subject: Re: New to Motorcycles...   \"\n",
      "Cosine Similarity is [[ 0.10606821]], for document \" Subject: Re: GGRRRrrr!! Cages double-parking motorcycles pisses me off!   \"\n",
      "Cosine Similarity is [[ 0.10300142]], for document \" Subject: Re: edu breaths   \"\n",
      "Cosine Similarity is [[ 0.09577946]], for document \" Subject: Re: First Bike??   \"\n",
      "Cosine Similarity is [[ 0.08896139]], for document \" Subject: European M/C Insurance   \"\n",
      "Cosine Similarity is [[ 0.0778002]], for document \" Subject: Re: GGRRRrrr!!  Cages double-parking motorcycles pisses me off!   \"\n",
      "Cosine Similarity is [[ 0.07241165]], for document \" Subject: Re: CNN California MC helmet law article   \"\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity_results('the fastest motorcycles', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
