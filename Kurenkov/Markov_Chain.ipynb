{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Перплексия новостей политики и спорта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование словарей частот 2 и 3-ргамм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grams_3 = {}\n",
    "gr = open('3grams-3.txt')\n",
    "for line in gr:\n",
    "    line = line.split('\\t')\n",
    "    try:        \n",
    "        grams_3[(line[1], line[3], line[5])] += int(line[0])\n",
    "    except KeyError:\n",
    "        grams_3[(line[1], line[3], line[5])] = int(line[0])\n",
    "gr.close()\n",
    "grams_2 = {}\n",
    "gr = open('2grams-3.txt')\n",
    "for line in gr:\n",
    "    line = line.split('\\t')\n",
    "    try:        \n",
    "        grams_2[(line[1], line[3])] += int(line[0])\n",
    "    except KeyError:\n",
    "        grams_2[(line[1], line[3])] = int(line[0])\n",
    "gr.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение ранее распарсенных новостей (примерно по 1200 нововсти в каждой теме)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txt = open(\"texts_politics.txt\")\n",
    "politics = []\n",
    "for line in txt:\n",
    "    current_line = nltk.word_tokenize(line.decode(\"utf-8\"))\n",
    "    current_line = [word.encode(\"utf-8\").decode(\"utf-8\").lower() for word in current_line if word not in string.punctuation\n",
    "                    and word not in [u'\\u2012', u'\\u2013', u'\\u2014', u'\\u2015', u'``', u\"''\"]]\n",
    "    politics = politics + current_line\n",
    "txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txt = open(\"texts_sport.txt\")\n",
    "sport = []\n",
    "for line in txt:\n",
    "    current_line = nltk.word_tokenize(line.decode(\"utf-8\"))\n",
    "    current_line = [word.encode(\"utf-8\").decode(\"utf-8\").lower() for word in current_line if word not in string.punctuation\n",
    "                    and word not in [u'\\u2012', u'\\u2013', u'\\u2014', u'\\u2015', u'``', u\"''\"]]\n",
    "    sport = sport + current_line\n",
    "txt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подсчет перплексии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Условная вероятность каждой отдельного слова при условии предыдущих вдух $p(w_i | w_{i-1}, w_{i-2})$ расчитывается как отношение 3-граммы $(w_i, w_{i-1}, w_{i-2})$ к 2-грамме $(w_{i-1}, w_{i-2})$, то есть $p(w_i | w_{i-1}, w_{i-2}) = \\frac{f(w_i, w_{i-1}, w_{i-2})}{f(w_{i-1}, w_{i-2})}$, где $f$ -- частота. \n",
    "#### Перплексия отдельного корпуса рассчитывается по формуле $2^{-\\frac{1}{N}\\sum_{i = 2}^N\\log_2p(w_i | w_{i-1}, w_{i-2})}$. (Пренебрегаем первыми двумя словами первого текста, а также границами между предложения и текстами.)\n",
    "#### Условная вероятность неизвестной 3-раммы пологается равной одно десятой минимальной известной вероятности. Сумма значений условных вероятностей для неизвестных 3-грамм равномеоно \"отбирается\" от известных вероятностей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sum_probability = 0\n",
    "unknown_words = 0\n",
    "min_probability = 1\n",
    "sum_log = 0\n",
    "\n",
    "for i in range(2, len(politics)):\n",
    "    try:\n",
    "        current_probability = (grams_3[(politics[i-2].encode(\"utf-8\"), politics[i-1].encode(\"utf-8\"), politics[i].encode(\"utf-8\") + \"\\n\")] + 0.0) / grams_2[\n",
    "            (politics[i-2].encode(\"utf-8\"), politics[i-1].encode(\"utf-8\") + \"\\n\")]\n",
    "        sum_probability += current_probability\n",
    "        if current_probability < min_probability:\n",
    "            min_probability = current_probability\n",
    "    except KeyError:\n",
    "        unknown_words +=1\n",
    "\n",
    "known_words = len(politics) - 2 - unknown_words\n",
    "min_probability /= 10\n",
    "probability_to_substract = (unknown_words * min_probability + 0.0) / known_words\n",
    "\n",
    "for i in range(2, len(politics)):\n",
    "    try:\n",
    "        current_probability = (grams_3[(politics[i-2].encode(\"utf-8\"), politics[i-1].encode(\"utf-8\"), politics[i].encode(\"utf-8\") + \"\\n\")] + 0.0) / grams_2[\n",
    "            (politics[i-2].encode(\"utf-8\"), politics[i-1].encode(\"utf-8\") + \"\\n\")]\n",
    "        sum_log += math.log(current_probability - probability_to_substract, 2)\n",
    "    except KeyError:\n",
    "        sum_log += math.log(min_probability, 2)\n",
    "        \n",
    "sum_log_politics = sum_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum_probability = 0\n",
    "unknown_words = 0\n",
    "min_probability = 1\n",
    "sum_log = 0\n",
    "\n",
    "for i in range(2, len(sport)):\n",
    "    try:\n",
    "        current_probability = (grams_3[(sport[i-2].encode(\"utf-8\"), sport[i-1].encode(\"utf-8\"), sport[i].encode(\"utf-8\") + \"\\n\")] + 0.0) / grams_2[\n",
    "            (sport[i-2].encode(\"utf-8\"), sport[i-1].encode(\"utf-8\") + \"\\n\")]\n",
    "        sum_probability += current_probability\n",
    "        if current_probability < min_probability:\n",
    "            min_probability = current_probability\n",
    "    except KeyError:\n",
    "        unknown_words +=1\n",
    "\n",
    "known_words = len(sport) - 2 - unknown_words\n",
    "min_probability /= 10\n",
    "probability_to_substract = (unknown_words * min_probability + 0.0) / known_words\n",
    "\n",
    "\n",
    "for i in range(2, len(sport)):\n",
    "    try:\n",
    "        current_probability = (grams_3[(sport[i-2].encode(\"utf-8\"), sport[i-1].encode(\"utf-8\"), sport[i].encode(\"utf-8\") + \"\\n\")] + 0.0) / grams_2[\n",
    "            (sport[i-2].encode(\"utf-8\"), sport[i-1].encode(\"utf-8\") + \"\\n\")]\n",
    "        sum_log += math.log(current_probability - probability_to_substract, 2)\n",
    "    except KeyError:\n",
    "        sum_log += math.log(min_probability, 2)\n",
    "        \n",
    "sum_log_sport = sum_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Perplexity for politics news = ', 102299.81971244352)\n",
      "('Perplexity for sport news = ', 167476.07101836757)\n"
     ]
    }
   ],
   "source": [
    "print(\"Perplexity for politics news = \",2**(-sum_log_politics / len(politics)))\n",
    "print(\"Perplexity for sport news = \",2**(-sum_log_sport / len(sport)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод: Корпус \"Политика\" лучше соответствует построенной маковской модели языва 2-ого порядка, чем корпус \"Спорт\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
